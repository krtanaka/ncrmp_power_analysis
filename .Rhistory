<<<<<<< HEAD
if (response_variable == "trophic_biomass") {
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = ifelse(TROPHIC_MONREP == sp, BIOMASS_G_M2*0.001, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = median(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
}
if (response_variable == "coral_cover") {
load("data/BenthicCover_2010-2020_Tier1_SITE_MHI_w_CRM.RData") #live coral cover, only for MHI, with CRM_Bathy data
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = CORAL,
DEPTH = ifelse(DEPTH_e == 0, DEPTH_e*-1 + 0.1, DEPTH_e*-1)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = median(response, na.rm = T),
n = n())
hist(df$response, main = paste0(sp, "_cover"))
}
if (response_variable == "coral_density") {
load("data/BenthicREA_sitedata_TAXONCODE.RData_MHI_w_CRM.RData") #live coral cover, only for MHI, with CRM_Bathy data
if (sp == "AdColDen") df = df %>% mutate(response = AdColDen)
if (sp == "JuvColDen") df = df %>% mutate(response = JuvColDen)
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate( DEPTH = ifelse(DEPTH_e == 0, DEPTH_e*-1 + 0.1, DEPTH_e*-1)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
hist(df$response, main = paste0(sp, "_coral_density"))
}
# north-south gradient
df %>%
group_by(ISLAND) %>%
summarise(n = mean(response, na.rm = T),
lat = mean(LATITUDE)) %>%
arrange(desc(lat))
zone <- (floor((df$LONGITUDE[1] + 180)/6) %% 60) + 1
xy_utm = as.data.frame(cbind(utm = project(as.matrix(df[, c("LONGITUDE", "LATITUDE")]), paste0("+proj=utm +units=km +zone=", zone))))
colnames(xy_utm) = c("X", "Y")
df = cbind(df, xy_utm)
# n_knots = 300
n_knots = 100 # a coarse mesh for speed
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
library(sdmTMB)
library(dplyr)
library(ggplot2)
library(rgdal)
library(colorRamps)
library(patchwork)
rm(list = ls())
# 4 functional groups
# live coral cover
# adult juvenile density
# for Uku:
# Total numerical density estimates (individuals per 100 m2) were obtained by dividing fish counts in each survey by the survey area (353 m2 from two 15-m diameter survey cylinders) and multiplying by 100. - Nadon et al. 2020
region = "MHI"
uku_or_not = F
# load("data/ALL_REA_FISH_RAW.rdata")
# df %>%
#   subset(REGION == region) %>%
#   group_by(TAXONNAME) %>%
#   summarise(n = sum(BIOMASS_G_M2, na.rm = T)) %>%
#   # summarise(n = sum(COUNT, na.rm = T)) %>%
#   mutate(freq = n/sum(n)) %>%
#   arrange(desc(freq)) %>%
#   top_n(5)
=======
sets <- cells[, .SD[sample(.N, strat_sets, replace = resample_cells)],
by = c("sim", "year", "strat")]
sets[, `:=`(cell_sets, .N), by = c("sim", "year", "cell")]
sets$set <- seq(nrow(sets))
sets
setkeyv(sets, c("sim", "year", "cell"))
sp_I <- data.table(sim$sp_N[, c("cell", "year", "N")])
i <- rep(seq(nrow(sp_I)), times = n_sims)
s <- rep(seq(n_sims), each = nrow(sp_I))
sp_I <- sp_I[i, ]
sp_I$sim <- s
setdet <- merge(sets, sp_I, by = c("sim", "year", "cell"))
setdet$n <- stats::rbinom(rep(1, nrow(setdet)),
size = round(setdet$N/setdet$cell_sets),
# prob = (setdet$tow_area/setdet$cell_area) * q(setdet$age))
prob = (setdet$tow_area/setdet$cell_area))
setkeyv(setdet, "set")
setkeyv(sets, "set")
sim$I <- I
sim$setdet <- setdet
setdet <- sim$setdet
data = list(setdet = setdet)
data$setdet <- data$setdet[, c("sim",
"year",
"division",
"strat",
"strat_area",
"tow_area",
"set",
"n"),
with = FALSE]
data = data$setdet
data
metric = "n"
strat_groups = c("sim", "year", "division", "strat", "strat_area", "tow_area")
survey_groups = c("sim", "year")
confidence = 95
Nh <- strat_area <- tow_area <- Wh <- total <- sumYh <- nh <- gh <- meanYh <- varYh <- meanYst_lcl <- meanYst <- varYst <- df <- meanYst_ucl <- sumYst <- N <- sumYst_lcl <- sumYst_ucl <- NULL
lc <- (100 - confidence)/200; lc
uc <- (100 - confidence)/200 + (confidence/100); uc
d <- copy(data)
d <- d[, c(strat_groups, metric), with = FALSE]
setnames(d, names(d), c(strat_groups, "metric"))
setkeyv(d, strat_groups)
strat_tab <- d[, list(sumYh = sum(metric), # sum of samples (n)
meanYh = mean(metric, na.rm = T), # mean of samples (n)
varYh = stats::var(metric, na.rm = T), # variance of samples (n)
nh = .N), # number of strata
by = strat_groups]; strat_tab
strat_tab[, `:=`(Nh, strat_area/tow_area)]; strat_tab
strat_tab[, `:=`(Wh, Nh/sum(Nh)), by = survey_groups]; strat_tab
strat_tab[, `:=`(total, Nh * sumYh/nh)]; strat_tab
strat_tab[, `:=`(gh, Nh * (Nh - nh)/nh)]; strat_tab
survey_tab <- strat_tab[, list(n = sum(nh, na.rm = T),
N = sum(Nh, na.rm = T),
meanYst = sum(Wh * meanYh),
varYst = (1/((sum(Nh))^2)) * sum(gh * varYh),
df = ((sum(gh * varYh))^2)/(sum((gh^2 * varYh^2)/(nh - 1)))), by = survey_groups]; survey_tab
survey_tab[, `:=`(meanYst_lcl, (meanYst - (sqrt(varYst)) * abs(stats::qt(lc, df))))]; survey_tab
survey_tab[, `:=`(meanYst_ucl, (meanYst + (sqrt(varYst)) * abs(stats::qt(lc, df))))]; survey_tab
survey_tab[, `:=`(sumYst, N * meanYst)]; survey_tab
survey_tab[, `:=`(sumYst_lcl, (sumYst - abs(stats::qt(lc, df)) * N * sqrt(varYst)))]; survey_tab
survey_tab[, `:=`(sumYst_ucl, (sumYst + abs(stats::qt(lc, df)) * N * sqrt(varYst)))]; survey_tab
survey_tab[sapply(survey_tab, is.nan)] <- NA
survey_tab <- survey_tab[, c(survey_groups,
"n",
"N",
"df",
"varYst",
"meanYst",
"meanYst_lcl",
"meanYst_ucl",
"sumYst",
"sumYst_lcl",
"sumYst_ucl"),
with = FALSE]
survey_tab$varYst <- sqrt(survey_tab$varYst)
setnames(survey_tab, names(survey_tab), c(survey_groups,
"sets",
"sampling_units",
"df",
"sd",
"mean",
"mean_lcl",
"mean_ucl",
"total",
"total_lcl",
"total_ucl"))
survey_tab
sim$total_strat = survey_tab
total <- NULL
I_hat <- sim$total_strat[, list(sim, year, total)]
names(I_hat) <- c("sim", "year", "I_hat")
I <- data.frame(year = sim$years, I = colSums(sim$I))
comp <- merge(I_hat, I, by = "year")
comp$error <- comp$I_hat - comp$I
means <- error_stats(comp$error)
sim$total_strat_error <- comp
sim$total_strat_error_stats <- means
I_hat <- sim$length_strat[, list(sim, year, length, total)]
sim$total_strat_error_stats
sim$total_strat_error
df = sim$total_strat_error
me = formatC(sim$total_strat_error_stats[1], digits = 3)
mae = formatC(sim$total_strat_error_stats[2], digits = 3)
mse = formatC(sim$total_strat_error_stats[3], digits = 3)
rmse = formatC(sim$total_strat_error_stats[4], digits = 3)
label = paste0("ME = ", me, "\n", "MAE = ", mae, "\n", "MSE = ", mse, "\n", "RMSE = ", rmse)
strata = sim$grid_xy %>%
mutate(x = round(x/0.5, digits = 0),
y = round(y/0.5, digits = 0)) %>%
group_by(x, y) %>%
summarise(strat = round(mean(strat), digits = 0),
depth = mean(depth)) %>%
ggplot(aes(x, y)) +
coord_fixed() +
geom_raster(aes(fill = factor(strat))) +
theme_minimal() +
ylab("Northing (km)") + xlab("Easting (km)") +
theme(legend.position = "none") +
labs(
title = "",
subtitle = paste0(paste0(island, "\n", "# of strata = ", length(unique(sim$grid_xy$strat)))))
if (response_scale == "biomass") ylab_scale = "biomass (g)"
if (response_scale == "count") ylab_scale = "abundance (n)"
sim_output = df %>%
ggplot() +
geom_line(aes(year, I_hat, color = factor(sim), alpha = 0.2), show.legend = F) +
geom_line(aes(year, I), size = 2, color = "red") +
# scale_color_viridis_d() +
# dark_theme_minimal() +
theme_minimal() +
ylab(ylab_scale) +
labs(
title = "",
subtitle = paste0("Survey target = ", sp, "\n",
"Total # of surveyed sites = ", total_sample, "\n",
"Min # of sets per strat = ", min_sets, "\n",
"Number of simulations = ", n_sims))+
annotate(label = label,
geom = "text",
x = Inf,
y = Inf,
size = 4,
hjust = 1,
vjust = 1)
# png(paste0("outputs/", sp, "_", island, ".png"), res = 100, units = "in", height = 4, width = 8)
strata + sim_output
png(paste0("outputs/", sp, "_", island, ".png"), res = 100, units = "in", height = 4, width = 8)
strata + sim_output
dev.off()
n_sims = 100 # number of simulations
total_sample = 100 # total sample efforts you want to deploy
min_sets = 2 # minimum number of sets per strat
set_den = 2/1000 # number of sets per [grid unit = km] squared)
trawl_dim = c(0.01, 0.0353) # 0.000353 sq.km (353 sq.m) from two 15-m diameter survey cylinders
resample_cells = F
n <- id <- division <- strat <- N <- NULL
# sets <- sim_sets(sim,
#                  resample_cells = resample_cells,
#                  n_sims = n_sims,
#                  trawl_dim = trawl_dim,
#                  set_den = set_den,
#                  min_sets = min_sets)
strat_sets <- cell_sets <- NULL
cells <- data.table(rasterToPoints(sim$grid))
strat_det <- cells[, list(strat_cells = .N), by = "strat"]; strat_det
strat_det$tow_area <- prod(trawl_dim); strat_det
strat_det$cell_area <- prod(res(sim$grid)); strat_det
strat_det$strat_area <- strat_det$strat_cells * prod(res(sim$grid)); strat_det
strat_det$strat_sets <- round(strat_det$strat_area * set_den); strat_det
strat_det$strat_sets = round((total_sample * strat_det$strat_area) / sum(strat_det$strat_area), 0); strat_det
strat_det$strat_sets[strat_det$strat_sets < min_sets] <- min_sets; strat_det # make sure minimum number of sets per strat is not 0 or 1
cells <- merge(cells, strat_det, by = c("strat")) # add "strat" "strat_cells" "tow_area" ...
i <- rep(seq(nrow(cells)), times = length(sim$years)) # number of cells * number of years
y <- rep(sim$years, each = nrow(cells)) # number of years * number of cells
cells <- cells[i, ] # increase the number of rows by number or years
cells$year <- y
i <- rep(seq(nrow(cells)), times = n_sims) # number of cells * number of simulations
s <- rep(seq(n_sims), each = nrow(cells)) # number of simulations * number of cells
cells <- cells[i, ] # increase the number of rows by number or simulations
cells$sim <- s
# .SD = "Subset of Data.table"
# .N = number of instances
# strat_sets, see unique(cells$strat_sets)
sets <- cells[, .SD[sample(.N, strat_sets, replace = resample_cells)],
by = c("sim", "year", "strat")]
sets[, `:=`(cell_sets, .N), by = c("sim", "year", "cell")]
sets$set <- seq(nrow(sets))
sets
setkeyv(sets, c("sim", "year", "cell"))
sp_I <- data.table(sim$sp_N[, c("cell", "year", "N")])
i <- rep(seq(nrow(sp_I)), times = n_sims)
s <- rep(seq(n_sims), each = nrow(sp_I))
sp_I <- sp_I[i, ]
sp_I$sim <- s
setdet <- merge(sets, sp_I, by = c("sim", "year", "cell"))
setdet$n <- stats::rbinom(rep(1, nrow(setdet)),
size = round(setdet$N/setdet$cell_sets),
# prob = (setdet$tow_area/setdet$cell_area) * q(setdet$age))
prob = (setdet$tow_area/setdet$cell_area))
setkeyv(setdet, "set")
setkeyv(sets, "set")
sim$I <- I
sim$setdet <- setdet
setdet <- sim$setdet
data = list(setdet = setdet)
data$setdet <- data$setdet[, c("sim",
"year",
"division",
"strat",
"strat_area",
"tow_area",
"set",
"n"),
with = FALSE]
data = data$setdet
data
metric = "n"
strat_groups = c("sim", "year", "division", "strat", "strat_area", "tow_area")
survey_groups = c("sim", "year")
confidence = 95
Nh <- strat_area <- tow_area <- Wh <- total <- sumYh <- nh <- gh <- meanYh <- varYh <- meanYst_lcl <- meanYst <- varYst <- df <- meanYst_ucl <- sumYst <- N <- sumYst_lcl <- sumYst_ucl <- NULL
lc <- (100 - confidence)/200; lc
uc <- (100 - confidence)/200 + (confidence/100); uc
d <- copy(data)
d <- d[, c(strat_groups, metric), with = FALSE]
setnames(d, names(d), c(strat_groups, "metric"))
setkeyv(d, strat_groups)
strat_tab <- d[, list(sumYh = sum(metric), # sum of samples (n)
meanYh = mean(metric, na.rm = T), # mean of samples (n)
varYh = stats::var(metric, na.rm = T), # variance of samples (n)
nh = .N), # number of strata
by = strat_groups]; strat_tab
strat_tab[, `:=`(Nh, strat_area/tow_area)]; strat_tab
strat_tab[, `:=`(Wh, Nh/sum(Nh)), by = survey_groups]; strat_tab
strat_tab[, `:=`(total, Nh * sumYh/nh)]; strat_tab
strat_tab[, `:=`(gh, Nh * (Nh - nh)/nh)]; strat_tab
survey_tab <- strat_tab[, list(n = sum(nh, na.rm = T),
N = sum(Nh, na.rm = T),
meanYst = sum(Wh * meanYh),
varYst = (1/((sum(Nh))^2)) * sum(gh * varYh),
df = ((sum(gh * varYh))^2)/(sum((gh^2 * varYh^2)/(nh - 1)))), by = survey_groups]; survey_tab
survey_tab[, `:=`(meanYst_lcl, (meanYst - (sqrt(varYst)) * abs(stats::qt(lc, df))))]; survey_tab
survey_tab[, `:=`(meanYst_ucl, (meanYst + (sqrt(varYst)) * abs(stats::qt(lc, df))))]; survey_tab
survey_tab[, `:=`(sumYst, N * meanYst)]; survey_tab
survey_tab[, `:=`(sumYst_lcl, (sumYst - abs(stats::qt(lc, df)) * N * sqrt(varYst)))]; survey_tab
survey_tab[, `:=`(sumYst_ucl, (sumYst + abs(stats::qt(lc, df)) * N * sqrt(varYst)))]; survey_tab
survey_tab[sapply(survey_tab, is.nan)] <- NA
survey_tab <- survey_tab[, c(survey_groups,
"n",
"N",
"df",
"varYst",
"meanYst",
"meanYst_lcl",
"meanYst_ucl",
"sumYst",
"sumYst_lcl",
"sumYst_ucl"),
with = FALSE]
survey_tab$varYst <- sqrt(survey_tab$varYst)
setnames(survey_tab, names(survey_tab), c(survey_groups,
"sets",
"sampling_units",
"df",
"sd",
"mean",
"mean_lcl",
"mean_ucl",
"total",
"total_lcl",
"total_ucl"))
survey_tab
sim$total_strat = survey_tab
total <- NULL
I_hat <- sim$total_strat[, list(sim, year, total)]
names(I_hat) <- c("sim", "year", "I_hat")
I <- data.frame(year = sim$years, I = colSums(sim$I))
comp <- merge(I_hat, I, by = "year")
comp$error <- comp$I_hat - comp$I
means <- error_stats(comp$error)
sim$total_strat_error <- comp
sim$total_strat_error_stats <- means
I_hat <- sim$length_strat[, list(sim, year, length, total)]
sim$total_strat_error_stats
sim$total_strat_error
df = sim$total_strat_error
me = formatC(sim$total_strat_error_stats[1], digits = 3)
mae = formatC(sim$total_strat_error_stats[2], digits = 3)
mse = formatC(sim$total_strat_error_stats[3], digits = 3)
rmse = formatC(sim$total_strat_error_stats[4], digits = 3)
label = paste0("ME = ", me, "\n", "MAE = ", mae, "\n", "MSE = ", mse, "\n", "RMSE = ", rmse)
strata = sim$grid_xy %>%
mutate(x = round(x/0.5, digits = 0),
y = round(y/0.5, digits = 0)) %>%
group_by(x, y) %>%
summarise(strat = round(mean(strat), digits = 0),
depth = mean(depth)) %>%
ggplot(aes(x, y)) +
coord_fixed() +
geom_raster(aes(fill = factor(strat))) +
theme_minimal() +
ylab("Northing (km)") + xlab("Easting (km)") +
theme(legend.position = "none") +
labs(
title = "",
subtitle = paste0(paste0(island, "\n", "# of strata = ", length(unique(sim$grid_xy$strat)))))
if (response_scale == "biomass") ylab_scale = "biomass (g)"
if (response_scale == "count") ylab_scale = "abundance (n)"
sim_output = df %>%
ggplot() +
geom_line(aes(year, I_hat, color = factor(sim), alpha = 0.2), show.legend = F) +
geom_line(aes(year, I), size = 2, color = "red") +
# scale_color_viridis_d() +
# dark_theme_minimal() +
theme_minimal() +
ylab(ylab_scale) +
labs(
title = "",
subtitle = paste0("Survey target = ", sp, "\n",
"Total # of surveyed sites = ", total_sample, "\n",
"Min # of sets per strat = ", min_sets, "\n",
"Number of simulations = ", n_sims))+
annotate(label = label,
geom = "text",
x = Inf,
y = Inf,
size = 4,
hjust = 1,
vjust = 1)
png(paste0("outputs/", sp, "_", island, ".png"), res = 100, units = "in", height = 4, width = 8)
strata + sim_output
dev.off()
strata + sim_output
# clean work station
rm(list = ls())
library(raster)
library(dplyr)
library(ggplot2)
library(readr)
# set working directory
setwd(paste0("/Users/", Sys.info()[7], "/Desktop"))
# load spatial grid
df = raster("jplG1SST_b799_dd6c_7662.nc") # spatial grids around MHIs around at 1-km resolution
# clean work station
rm(list = ls())
<<<<<<< HEAD
region = "MHI"
uku_or_not = F
>>>>>>> 66df00f6b72ccd989d9f4e988ae01e780e3ee943
islands = c("Kauai", #1
"Lehua", #2
"Niihau", #3
"Kaula", #4
"Oahu", #5
"Molokai", #6
"Maui", #7
"Lanai", #8
"Molokini", #9
"Kahoolawe", #10
<<<<<<< HEAD
"Hawaii")#[11]
response_variable = "trophic_biomass"; sp = c("PISCIVORE", "PLANKTIVORE", "PRIMARY", "SECONDARY")[1]
=======
"Hawaii")[5]
response_variable = "fish_count";      sp = ifelse(uku_or_not == T, "Aprion virescens", "Chromis vanderbilti")
response_variable = "fish_biomass";    sp = ifelse(uku_or_not == T, "Aprion virescens", "Acanthurus olivaceus")
response_variable = "trophic_biomass"; sp = c("PISCIVORE", "PLANKTIVORE", "PRIMARY", "SECONDARY")[2]
>>>>>>> 66df00f6b72ccd989d9f4e988ae01e780e3ee943
if (response_variable == "fish_count") {
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
# mutate(response = ifelse(TAXONNAME == sp, COUNT*100, 0)) %>%
mutate(response = ifelse(TAXONNAME == sp, COUNT, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = mean(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
}
if (response_variable == "fish_biomass") {
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = ifelse(TAXONNAME == sp, BIOMASS_G_M2, 0)) %>%
# mutate(response = ifelse(TAXONNAME == sp, BIOMASS_G_M2*0.001, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = median(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
}
if (response_variable == "trophic_biomass") {
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = ifelse(TROPHIC_MONREP == sp, BIOMASS_G_M2*0.001, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = median(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
}
if (response_variable == "coral_cover") {
load("data/BenthicCover_2010-2020_Tier1_SITE_MHI_w_CRM.RData") #live coral cover, only for MHI, with CRM_Bathy data
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = CORAL,
DEPTH = ifelse(DEPTH_e == 0, DEPTH_e*-1 + 0.1, DEPTH_e*-1)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = median(response, na.rm = T),
n = n())
hist(df$response, main = paste0(sp, "_cover"))
}
if (response_variable == "coral_density") {
load("data/BenthicREA_sitedata_TAXONCODE.RData_MHI_w_CRM.RData") #live coral cover, only for MHI, with CRM_Bathy data
if (sp == "AdColDen") df = df %>% mutate(response = AdColDen)
if (sp == "JuvColDen") df = df %>% mutate(response = JuvColDen)
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate( DEPTH = ifelse(DEPTH_e == 0, DEPTH_e*-1 + 0.1, DEPTH_e*-1)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
hist(df$response, main = paste0(sp, "_coral_density"))
}
# north-south gradient
df %>%
group_by(ISLAND) %>%
summarise(n = mean(response, na.rm = T),
lat = mean(LATITUDE)) %>%
arrange(desc(lat))
zone <- (floor((df$LONGITUDE[1] + 180)/6) %% 60) + 1
xy_utm = as.data.frame(cbind(utm = project(as.matrix(df[, c("LONGITUDE", "LATITUDE")]), paste0("+proj=utm +units=km +zone=", zone))))
colnames(xy_utm) = c("X", "Y")
df = cbind(df, xy_utm)
n_knots = 300
# n_knots = 100 # a coarse mesh for speed
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
# par(mfrow = c(1,2))
# plot(xy_utm, pch = ".", bty = 'n')
plot(rea_spde, pch = ".", bty = "n"); axis(1); axis(2)
png("outputs/SPDE_mesh_field.png", height = 5, width = 5, units = "in", res = 100)
# par(mfrow = c(1,2))
# plot(xy_utm, pch = ".", bty = 'n')
plot(rea_spde, pch = ".", bty = "n"); axis(1); axis(2)
dev.off()
n_knots = 100 # a coarse mesh for speed
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
<<<<<<< HEAD
>>>>>>> a0952ce0d10c90d2141bd3b9e37c50641edb3d8c
library(sdmTMB)
library(dplyr)
library(ggplot2)
library(rgdal)
library(colorRamps)
library(patchwork)
rm(list = ls())
# 4 functional groups
# live coral cover
# adult juvenile density
# for Uku:
# Total numerical density estimates (individuals per 100 m2) were obtained by dividing fish counts in each survey by the survey area (353 m2 from two 15-m diameter survey cylinders) and multiplying by 100. - Nadon et al. 2020
region = "MHI"
uku_or_not = F
# load("data/ALL_REA_FISH_RAW.rdata")
# df %>%
#   subset(REGION == region) %>%
#   group_by(TAXONNAME) %>%
#   summarise(n = sum(BIOMASS_G_M2, na.rm = T)) %>%
#   # summarise(n = sum(COUNT, na.rm = T)) %>%
#   mutate(freq = n/sum(n)) %>%
#   arrange(desc(freq)) %>%
#   top_n(5)
islands = c("Kauai", #1
"Lehua", #2
"Niihau", #3
"Kaula", #4
"Oahu", #5
"Molokai", #6
"Maui", #7
"Lanai", #8
"Molokini", #9
"Kahoolawe", #10
"Hawaii")[5]
library(sdmTMB)
library(dplyr)
library(ggplot2)
library(rgdal)
library(colorRamps)
library(patchwork)
rm(list = ls())
# 4 functional groups
# live coral cover
# adult juvenile density
# for Uku:
# Total numerical density estimates (individuals per 100 m2) were obtained by dividing fish counts in each survey by the survey area (353 m2 from two 15-m diameter survey cylinders) and multiplying by 100. - Nadon et al. 2020
region = "MHI"
uku_or_not = F
# load("data/ALL_REA_FISH_RAW.rdata")
# df %>%
#   subset(REGION == region) %>%
#   group_by(TAXONNAME) %>%
#   summarise(n = sum(BIOMASS_G_M2, na.rm = T)) %>%
#   # summarise(n = sum(COUNT, na.rm = T)) %>%
#   mutate(freq = n/sum(n)) %>%
#   arrange(desc(freq)) %>%
#   top_n(5)
islands = c("Kauai", #1
"Lehua", #2
"Niihau", #3
"Kaula", #4
"Oahu", #5
"Molokai", #6
"Maui", #7
"Lanai", #8
"Molokini", #9
"Kahoolawe", #10
"Hawaii")[5]
response_variable = "trophic_biomass"; sp = c("PISCIVORE", "PLANKTIVORE", "PRIMARY", "SECONDARY")[2]
if (response_variable == "trophic_biomass") {
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = ifelse(TROPHIC_MONREP == sp, BIOMASS_G_M2*0.001, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = median(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
}
# north-south gradient
df %>%
group_by(ISLAND) %>%
summarise(n = mean(response, na.rm = T),
lat = mean(LATITUDE)) %>%
arrange(desc(lat))
zone <- (floor((df$LONGITUDE[1] + 180)/6) %% 60) + 1
xy_utm = as.data.frame(cbind(utm = project(as.matrix(df[, c("LONGITUDE", "LATITUDE")]), paste0("+proj=utm +units=km +zone=", zone))))
colnames(xy_utm) = c("X", "Y")
df = cbind(df, xy_utm)
n_knots = 300
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
n_knots = 50
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
# n_knots = 100 # a coarse mesh for speed
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
# WAVE ACTION CALCULATOR #
## this code assigns wave action per juvenile coral site using two wave data files
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
library(ggsn)
library(ggspatial)
library(ggrepel)
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
library(ggsn)
library(ggspatial)
library(ggrepel)
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # wave data generated from the 15m depth contour to help fill in the gaps from where the fish sites weren't surveyed
fish <- read.csv("FISH_waves_1979_2010.csv") # wave data from historical fish sites
#Data cleanup
head(cont)
colnames(cont)
cont <- cont[ which(cont$BAD_FLAG == 0),] # remove the bad flags
cont$X2011 <- NULL # remove 2011 and 2012 data so both datasets have same year range
cont$X2012 <- NULL
cont$BAD_FLAG <- NULL
head(fish)
colnames(fish)
fish<-fish%>% dplyr::filter(Site!="GUA-01310") #remove this site because it doesn't have a lat and long
fish<-fish%>% dplyr::filter(fish$BAD_FLAG == 0) #remove this site because it doesn't have a lat and long
fish$Wave.Power..kwhr.m. <- NULL
fish$ISL <- substr(fish$Site, 1, 3)
fish$Site <- NULL
fish$BAD_FLAG <- NULL
fish <- fish[,c(1,2,35,3:34)] # reorder
all <- rbind(fish, cont) # combined data sets
nrow(fish)
nrow(cont)
# calculate mean and median per coordinate across all years- Tom has concerns about using mean as a summary statistic
all_2<-all %>%
rowwise() %>%
dplyr::mutate(means = mean(c_across(X1979:X2010), na.rm=T),medians = median(c_across(X1979:X2010), na.rm=T))
head(as.data.frame(all_2))
# save full wave action dataframe as a new data set
write.csv(all_2, "WaveActionPacific_1997_2010.csv")
# convert to spatial points data frame
xy <- all_2[,c(1,2)]
all_sp <- SpatialPointsDataFrame(coords = xy, data = all_2,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
### read in juvenile data
juv<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_GENUS.csv")
#Clean up juvenile site data
juv<-juv%>%dplyr::filter(OBS_YEAR >2013)
levels(juv$MISSIONID)
juv<-juv[!juv$MISSIONID %in% c("MP1410","MP1512","MP1602","SE1602","MP2006"),]
juv$Year_Island<-paste(juv$OBS_YEAR,juv$ISLAND,sep="_")
juv$Year_Region<-paste(juv$OBS_YEAR,juv$REGION,sep="_")
juv<-juv[!juv$Year_Island %in% c("2017_Baker","2017_Jarvis","2017_Howland"),]
juv<-droplevels(juv);levels(juv$MISSIONID)
View(juv)
juvS<-subset(juv,GENUS_CODE=="SSSS")
juvS <- subset(juvS,select=c(ISLAND,SITE,LATITUDE,LONGITUDE)) # remove extra columns -- only need site name + coords
colnames(juvS)
#Read in islands shapefile
islands<-st_read("U:/GIS/Data/Pacific/islands.shp")
# WAVE ACTION CALCULATOR #
## this code assigns wave action per juvenile coral site using two wave data files
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
library(ggsn)
library(ggspatial)
library(ggrepel)
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # wave data generated from the 15m depth contour to help fill in the gaps from where the fish sites weren't surveyed
fish <- read.csv("FISH_waves_1979_2010.csv") # wave data from historical fish sites
#Data cleanup
head(cont)
colnames(cont)
cont <- cont[ which(cont$BAD_FLAG == 0),] # remove the bad flags
cont$X2011 <- NULL # remove 2011 and 2012 data so both datasets have same year range
cont$X2012 <- NULL
cont$BAD_FLAG <- NULL
head(fish)
colnames(fish)
fish<-fish%>% dplyr::filter(Site!="GUA-01310") #remove this site because it doesn't have a lat and long
fish<-fish%>% dplyr::filter(fish$BAD_FLAG == 0) #remove this site because it doesn't have a lat and long
fish$Wave.Power..kwhr.m. <- NULL
fish$ISL <- substr(fish$Site, 1, 3)
fish$Site <- NULL
fish$BAD_FLAG <- NULL
fish <- fish[,c(1,2,35,3:34)] # reorder
all <- rbind(fish, cont) # combined data sets
nrow(fish)
nrow(cont)
# calculate mean and median per coordinate across all years- Tom has concerns about using mean as a summary statistic
all_2<-all %>%
rowwise() %>%
dplyr::mutate(means = mean(c_across(X1979:X2010), na.rm=T),medians = median(c_across(X1979:X2010), na.rm=T))
head(as.data.frame(all_2))
# convert to spatial points data frame
xy <- all_2[,c(1,2)]
all_sp <- SpatialPointsDataFrame(coords = xy, data = all_2,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
### read in juvenile data
juv<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_GENUS.csv")
#Clean up juvenile site data
juv<-juv%>%dplyr::filter(OBS_YEAR >2013)
levels(juv$MISSIONID)
juv<-juv[!juv$MISSIONID %in% c("MP1410","MP1512","MP1602","SE1602","MP2006"),]
juv$Year_Island<-paste(juv$OBS_YEAR,juv$ISLAND,sep="_")
juv$Year_Region<-paste(juv$OBS_YEAR,juv$REGION,sep="_")
juv<-juv[!juv$Year_Island %in% c("2017_Baker","2017_Jarvis","2017_Howland"),]
juv<-droplevels(juv);levels(juv$MISSIONID)
View(juv)
juvS<-subset(juv,GENUS_CODE=="SSSS")
juvS <- subset(juvS,select=c(ISLAND,SITE,LATITUDE,LONGITUDE)) # remove extra columns -- only need site name + coords
colnames(juvS)
#Read in islands shapefile
islands<-st_read("U:/GIS/Data/Pacific/islands.shp")
#Plotting the wave and juvenile data for a subset of islands to check overlap
#Helpful website for plotting maps with ggplot https://r-spatial.org/r/2018/10/25/ggplot2-sf-2.html
Plot_WaveJuv<-function(d1,d2,d3,waveISL="OAH",juvISL="Oahu",xlim1,xlim2,ylim1,ylim2){
ggplot(data = d1) +
geom_sf() +
geom_point(data = subset(d2,ISL==waveISL), aes(x = x, y = y), size = 2, shape = 21, fill = "slateblue3") +
geom_point(data = subset(d3,ISLAND==juvISL),aes(x = LONGITUDE, y = LATITUDE), size = 2, shape = 8, color = "darkorange1") +
coord_sf(xlim = c(xlim1, xlim2), ylim = c(ylim1, ylim2), expand = FALSE)+
theme(panel.grid.major = element_line(color = gray(0.5), linetype = "dashed",
size = 0.5), panel.background = element_rect(fill = "aliceblue"))+
annotation_scale(location = "bl", width_hint = 0.4)
}
extent(subset(all_2,ISL=="OAH")) # identify extent of coordinates
Plot_WaveJuv(islands,all_2,juv,"OAH","Oahu",-158.5, -157.5,21.2, 21.8)
extent(subset(all_2,ISL=="KAH")) # identify extent of coordinates
Plot_WaveJuv(islands,all_2,juv,"KAH","Kahoolawe",-156.72, -156.5,20.5, 20.61)
extent(subset(all_2,ISL=="MAU"))
Plot_WaveJuv(islands,all_2,juv,"MAU","Maug",145.2, 145.25,20, 20.05)
extent(subset(all_2,ISL=="PAL"))
Plot_WaveJuv(islands,all_2,juv,"PAL","Palmyra",-162.2, -161.99,5.85,5.925)
extent(subset(all_2,ISL=="KIN"))
Plot_WaveJuv(islands,all_2,juv,"KIN","Kingman",-162.49, -162.3,6.35,6.47)
# convert juv data to spatial points data
xy_juv <- juvS[,c(4,3)]
juv_sp <- SpatialPointsDataFrame(coords = xy_juv, data = juvS,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
str(juv_sp)
### calculate the mean wave action values within 250m radius of each juv point
# source expanding extract function
source("M:/Environmental Data Summary/HelperCode/ExpandingExtract_Flex.R")
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
sites_waves
ExpandingExtract_Flex
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
all_sp
juv_sp
ExpandingExtract_Flex
ExpandingExtract_Flex
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
ExpandingExtract_Flex
### calculate the mean wave action values within 250m radius of each juv point
# source expanding extract function
source("M:/Environmental Data Summary/HelperCode/ExpandingExtract_Flex.R")
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
ExpandingExtract_Flex
head(sites_waves)
# convert juv data to spatial points data
xy_juv <- juvS[,c(4,3)]
juv_sp <- SpatialPointsDataFrame(coords = xy_juv, data = juvS,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
### calculate the mean wave action values within 250m radius of each juv point
# source expanding extract function
source("M:/Environmental Data Summary/HelperCode/ExpandingExtract_Flex.R")
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
ExpandingExtract_Flex
sessionInfo()
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
library(ggsn)
library(ggspatial)
library(ggrepel)
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # wave data generated from the 15m depth contour to help fill in the gaps from where the fish sites weren't surveyed
fish <- read.csv("FISH_waves_1979_2010.csv") # wave data from historical fish sites
#Data cleanup
head(cont)
colnames(cont)
cont <- cont[ which(cont$BAD_FLAG == 0),] # remove the bad flags
cont$X2011 <- NULL # remove 2011 and 2012 data so both datasets have same year range
cont$X2012 <- NULL
cont$BAD_FLAG <- NULL
head(fish)
colnames(fish)
fish<-fish%>% dplyr::filter(Site!="GUA-01310") #remove this site because it doesn't have a lat and long
fish<-fish%>% dplyr::filter(fish$BAD_FLAG == 0) #remove this site because it doesn't have a lat and long
fish$Wave.Power..kwhr.m. <- NULL
fish$ISL <- substr(fish$Site, 1, 3)
fish$Site <- NULL
fish$BAD_FLAG <- NULL
fish <- fish[,c(1,2,35,3:34)] # reorder
all <- rbind(fish, cont) # combined data sets
nrow(fish)
nrow(cont)
# calculate mean and median per coordinate across all years- Tom has concerns about using mean as a summary statistic
all_2<-all %>%
rowwise() %>%
dplyr::mutate(means = mean(c_across(X1979:X2010), na.rm=T),medians = median(c_across(X1979:X2010), na.rm=T))
head(as.data.frame(all_2))
# save full wave action dataframe as a new data set
write.csv(all_2, "WaveActionPacific_1997_2010.csv")
# convert to spatial points data frame
xy <- all_2[,c(1,2)]
all_sp <- SpatialPointsDataFrame(coords = xy, data = all_2,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
### read in juvenile data
juv<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_GENUS.csv")
#Clean up juvenile site data
juv<-juv%>%dplyr::filter(OBS_YEAR >2013)
levels(juv$MISSIONID)
juv<-juv[!juv$MISSIONID %in% c("MP1410","MP1512","MP1602","SE1602","MP2006"),]
juv$Year_Island<-paste(juv$OBS_YEAR,juv$ISLAND,sep="_")
juv$Year_Region<-paste(juv$OBS_YEAR,juv$REGION,sep="_")
juv<-juv[!juv$Year_Island %in% c("2017_Baker","2017_Jarvis","2017_Howland"),]
juv<-droplevels(juv);levels(juv$MISSIONID)
View(juv)
juvS<-subset(juv,GENUS_CODE=="SSSS")
juvS <- subset(juvS,select=c(ISLAND,SITE,LATITUDE,LONGITUDE)) # remove extra columns -- only need site name + coords
colnames(juvS)
#Read in islands shapefile
islands<-st_read("U:/GIS/Data/Pacific/islands.shp")
#Plotting the wave and juvenile data for a subset of islands to check overlap
#Helpful website for plotting maps with ggplot https://r-spatial.org/r/2018/10/25/ggplot2-sf-2.html
Plot_WaveJuv<-function(d1,d2,d3,waveISL="OAH",juvISL="Oahu",xlim1,xlim2,ylim1,ylim2){
ggplot(data = d1) +
geom_sf() +
geom_point(data = subset(d2,ISL==waveISL), aes(x = x, y = y), size = 2, shape = 21, fill = "slateblue3") +
geom_point(data = subset(d3,ISLAND==juvISL),aes(x = LONGITUDE, y = LATITUDE), size = 2, shape = 8, color = "darkorange1") +
coord_sf(xlim = c(xlim1, xlim2), ylim = c(ylim1, ylim2), expand = FALSE)+
theme(panel.grid.major = element_line(color = gray(0.5), linetype = "dashed",
size = 0.5), panel.background = element_rect(fill = "aliceblue"))+
annotation_scale(location = "bl", width_hint = 0.4)
}
extent(subset(all_2,ISL=="OAH")) # identify extent of coordinates
Plot_WaveJuv(islands,all_2,juv,"OAH","Oahu",-158.5, -157.5,21.2, 21.8)
extent(subset(all_2,ISL=="KAH")) # identify extent of coordinates
Plot_WaveJuv(islands,all_2,juv,"KAH","Kahoolawe",-156.72, -156.5,20.5, 20.61)
extent(subset(all_2,ISL=="MAU"))
Plot_WaveJuv(islands,all_2,juv,"MAU","Maug",145.2, 145.25,20, 20.05)
extent(subset(all_2,ISL=="PAL"))
Plot_WaveJuv(islands,all_2,juv,"PAL","Palmyra",-162.2, -161.99,5.85,5.925)
extent(subset(all_2,ISL=="KIN"))
Plot_WaveJuv(islands,all_2,juv,"KIN","Kingman",-162.49, -162.3,6.35,6.47)
# convert juv data to spatial points data
xy_juv <- juvS[,c(4,3)]
juv_sp <- SpatialPointsDataFrame(coords = xy_juv, data = juvS,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
str(juv_sp)
### calculate the mean wave action values within 250m radius of each juv point
# source expanding extract function
source("M:/Environmental Data Summary/HelperCode/ExpandingExtract_Flex.R")
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
sessionInfo()
=======
# par(mfrow = c(1,2))
# plot(xy_utm, pch = ".", bty = 'n')
plot(rea_spde, pch = ".", bty = "n"); axis(1); axis(2)
png("outputs/SPDE_mesh_field.png", height = 5, width = 5, units = "in", res = 100)
# par(mfrow = c(1,2))
# plot(xy_utm, pch = ".", bty = 'n')
plot(rea_spde, pch = ".", bty = "n"); axis(1); axis(2)
dev.off()
n_knots = 300
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
png(paste0("outputs/SPDE_mesh_field_", n_knots, ".png"), height = 5, width = 5, units = "in", res = 100)
# par(mfrow = c(1,2))
# plot(xy_utm, pch = ".", bty = 'n')
plot(rea_spde, pch = ".", bty = "n"); axis(1); axis(2)
dev.off()
n_knots = 100 # a coarse mesh for speed
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
png(paste0("outputs/SPDE_mesh_field_", n_knots, ".png"), height = 5, width = 5, units = "in", res = 100)
# par(mfrow = c(1,2))
# plot(xy_utm, pch = ".", bty = 'n')
plot(rea_spde, pch = ".", bty = "n"); axis(1); axis(2)
dev.off()
=======
library(raster)
library(dplyr)
library(ggplot2)
library(readr)
# set working directory
setwd(paste0("/Users/", Sys.info()[7], "/Desktop"))
# load spatial grid
df = raster("jplG1SST_b799_dd6c_7662.nc") # spatial grids around MHIs around at 1-km resolution
df = rasterToPoints(df)
df = as.data.frame(df[,1:2])
df$x = ifelse(df$x < 0, df$x + 360, df$x)
# load Maya's list of islands
is = read.csv("Reference Spreadsheet - Island_Extents.csv")
is$LEFT_XMIN = ifelse(is$LEFT_XMIN < 0, is$LEFT_XMIN + 360, is$LEFT_XMIN)
is$RIGHT_XMAX = ifelse(is$RIGHT_XMAX < 0, is$RIGHT_XMAX + 360, is$RIGHT_XMAX)
islands = is$ISLAND.CODE
# loop through the list, assign spatial sectors (NW, NE, SW, SE) for each island
mayas_islands = NULL
for (i in 1:length(islands)) {
# i = 1
island = is %>% subset(ISLAND.CODE == islands[i])
grid = df %>%
subset(x > island$RIGHT_XMAX) %>%
subset(x < island$LEFT_XMIN) %>%
subset(y < island$BOTTOM_YMIN) %>%
subset(y > island$TOP_YMAX)
grid$island = islands[i]
grid = grid %>%
group_by(island) %>%
mutate(medianY = median(y),
medianX = median(x),
NS = ifelse(y < medianY, "S", "N"),
EW = ifelse(x < medianX, "W", "E"),
NSEW = paste0(NS, EW))
mayas_islands = rbind(grid, mayas_islands)
print(islands[i])
}
# plot and check output
mayas_islands %>%
ggplot(aes(x, y, fill = NSEW)) +
geom_raster() +
scale_fill_viridis_d("") +
facet_wrap(.~island, scale = "free") +
theme_void()
colnames(mayas_islands)[1:2] = c("lon", "lat")
# export as a csv file
write_csv(mayas_islands, "Mayas_Islands.csv")
>>>>>>> f08a77348b9cca5533ffcab76f345be7f2eea586
>>>>>>> 66df00f6b72ccd989d9f4e988ae01e780e3ee943
