if (response_variable == "trophic_biomass") {
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = ifelse(TROPHIC_MONREP == sp, BIOMASS_G_M2*0.001, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = median(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
}
if (response_variable == "coral_cover") {
load("data/BenthicCover_2010-2020_Tier1_SITE_MHI_w_CRM.RData") #live coral cover, only for MHI, with CRM_Bathy data
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = CORAL,
DEPTH = ifelse(DEPTH_e == 0, DEPTH_e*-1 + 0.1, DEPTH_e*-1)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = median(response, na.rm = T),
n = n())
hist(df$response, main = paste0(sp, "_cover"))
}
if (response_variable == "coral_density") {
load("data/BenthicREA_sitedata_TAXONCODE.RData_MHI_w_CRM.RData") #live coral cover, only for MHI, with CRM_Bathy data
if (sp == "AdColDen") df = df %>% mutate(response = AdColDen)
if (sp == "JuvColDen") df = df %>% mutate(response = JuvColDen)
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate( DEPTH = ifelse(DEPTH_e == 0, DEPTH_e*-1 + 0.1, DEPTH_e*-1)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
hist(df$response, main = paste0(sp, "_coral_density"))
}
# north-south gradient
df %>%
group_by(ISLAND) %>%
summarise(n = mean(response, na.rm = T),
lat = mean(LATITUDE)) %>%
arrange(desc(lat))
zone <- (floor((df$LONGITUDE[1] + 180)/6) %% 60) + 1
xy_utm = as.data.frame(cbind(utm = project(as.matrix(df[, c("LONGITUDE", "LATITUDE")]), paste0("+proj=utm +units=km +zone=", zone))))
colnames(xy_utm) = c("X", "Y")
df = cbind(df, xy_utm)
# n_knots = 300
n_knots = 100 # a coarse mesh for speed
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
library(sdmTMB)
library(dplyr)
library(ggplot2)
library(rgdal)
library(colorRamps)
library(patchwork)
rm(list = ls())
# 4 functional groups
# live coral cover
# adult juvenile density
# for Uku:
# Total numerical density estimates (individuals per 100 m2) were obtained by dividing fish counts in each survey by the survey area (353 m2 from two 15-m diameter survey cylinders) and multiplying by 100. - Nadon et al. 2020
region = "MHI"
uku_or_not = F
# load("data/ALL_REA_FISH_RAW.rdata")
# df %>%
#   subset(REGION == region) %>%
#   group_by(TAXONNAME) %>%
#   summarise(n = sum(BIOMASS_G_M2, na.rm = T)) %>%
#   # summarise(n = sum(COUNT, na.rm = T)) %>%
#   mutate(freq = n/sum(n)) %>%
#   arrange(desc(freq)) %>%
#   top_n(5)
islands = c("Kauai", #1
"Lehua", #2
"Niihau", #3
"Kaula", #4
"Oahu", #5
"Molokai", #6
"Maui", #7
"Lanai", #8
"Molokini", #9
"Kahoolawe", #10
"Hawaii")#[11]
response_variable = "trophic_biomass"; sp = c("PISCIVORE", "PLANKTIVORE", "PRIMARY", "SECONDARY")[1]
if (response_variable == "fish_count") {
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
# mutate(response = ifelse(TAXONNAME == sp, COUNT*100, 0)) %>%
mutate(response = ifelse(TAXONNAME == sp, COUNT, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = mean(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
}
if (response_variable == "fish_biomass") {
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = ifelse(TAXONNAME == sp, BIOMASS_G_M2, 0)) %>%
# mutate(response = ifelse(TAXONNAME == sp, BIOMASS_G_M2*0.001, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = median(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
}
if (response_variable == "trophic_biomass") {
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = ifelse(TROPHIC_MONREP == sp, BIOMASS_G_M2*0.001, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = median(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
}
sp
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = ifelse(TROPHIC_MONREP == sp, BIOMASS_G_M2*0.001, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = median(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
# north-south gradient
df %>%
group_by(ISLAND) %>%
summarise(n = mean(response, na.rm = T),
lat = mean(LATITUDE)) %>%
arrange(desc(lat))
zone <- (floor((df$LONGITUDE[1] + 180)/6) %% 60) + 1
xy_utm = as.data.frame(cbind(utm = project(as.matrix(df[, c("LONGITUDE", "LATITUDE")]), paste0("+proj=utm +units=km +zone=", zone))))
colnames(xy_utm) = c("X", "Y")
df = cbind(df, xy_utm)
# n_knots = 300
n_knots = 100 # a coarse mesh for speed
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
>>>>>>> a0952ce0d10c90d2141bd3b9e37c50641edb3d8c
library(sdmTMB)
library(dplyr)
library(ggplot2)
library(rgdal)
library(colorRamps)
library(patchwork)
rm(list = ls())
# 4 functional groups
# live coral cover
# adult juvenile density
# for Uku:
# Total numerical density estimates (individuals per 100 m2) were obtained by dividing fish counts in each survey by the survey area (353 m2 from two 15-m diameter survey cylinders) and multiplying by 100. - Nadon et al. 2020
region = "MHI"
uku_or_not = F
# load("data/ALL_REA_FISH_RAW.rdata")
# df %>%
#   subset(REGION == region) %>%
#   group_by(TAXONNAME) %>%
#   summarise(n = sum(BIOMASS_G_M2, na.rm = T)) %>%
#   # summarise(n = sum(COUNT, na.rm = T)) %>%
#   mutate(freq = n/sum(n)) %>%
#   arrange(desc(freq)) %>%
#   top_n(5)
islands = c("Kauai", #1
"Lehua", #2
"Niihau", #3
"Kaula", #4
"Oahu", #5
"Molokai", #6
"Maui", #7
"Lanai", #8
"Molokini", #9
"Kahoolawe", #10
"Hawaii")[5]
library(sdmTMB)
library(dplyr)
library(ggplot2)
library(rgdal)
library(colorRamps)
library(patchwork)
rm(list = ls())
# 4 functional groups
# live coral cover
# adult juvenile density
# for Uku:
# Total numerical density estimates (individuals per 100 m2) were obtained by dividing fish counts in each survey by the survey area (353 m2 from two 15-m diameter survey cylinders) and multiplying by 100. - Nadon et al. 2020
region = "MHI"
uku_or_not = F
# load("data/ALL_REA_FISH_RAW.rdata")
# df %>%
#   subset(REGION == region) %>%
#   group_by(TAXONNAME) %>%
#   summarise(n = sum(BIOMASS_G_M2, na.rm = T)) %>%
#   # summarise(n = sum(COUNT, na.rm = T)) %>%
#   mutate(freq = n/sum(n)) %>%
#   arrange(desc(freq)) %>%
#   top_n(5)
islands = c("Kauai", #1
"Lehua", #2
"Niihau", #3
"Kaula", #4
"Oahu", #5
"Molokai", #6
"Maui", #7
"Lanai", #8
"Molokini", #9
"Kahoolawe", #10
"Hawaii")[5]
response_variable = "trophic_biomass"; sp = c("PISCIVORE", "PLANKTIVORE", "PRIMARY", "SECONDARY")[2]
if (response_variable == "trophic_biomass") {
load("data/rea/ALL_REA_FISH_RAW.rdata")
df = df %>%
subset(REGION == region & ISLAND %in% islands) %>%
mutate(response = ifelse(TROPHIC_MONREP == sp, BIOMASS_G_M2*0.001, 0)) %>%
group_by(LONGITUDE, LATITUDE, ISLAND, OBS_YEAR, DATE_, DEPTH) %>%
summarise(response = sum(response, na.rm = T))
df %>% ggplot(aes(response)) + geom_histogram() +
df %>% group_by(OBS_YEAR) %>% summarise(n = median(response)) %>% ggplot(aes(OBS_YEAR, n)) + geom_line()
}
# north-south gradient
df %>%
group_by(ISLAND) %>%
summarise(n = mean(response, na.rm = T),
lat = mean(LATITUDE)) %>%
arrange(desc(lat))
zone <- (floor((df$LONGITUDE[1] + 180)/6) %% 60) + 1
xy_utm = as.data.frame(cbind(utm = project(as.matrix(df[, c("LONGITUDE", "LATITUDE")]), paste0("+proj=utm +units=km +zone=", zone))))
colnames(xy_utm) = c("X", "Y")
df = cbind(df, xy_utm)
n_knots = 300
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
n_knots = 50
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
# n_knots = 100 # a coarse mesh for speed
rea_spde <- make_mesh(df, c("X", "Y"), n_knots = n_knots, type = "cutoff_search")
# WAVE ACTION CALCULATOR #
## this code assigns wave action per juvenile coral site using two wave data files
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
library(ggsn)
library(ggspatial)
library(ggrepel)
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
library(ggsn)
library(ggspatial)
library(ggrepel)
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # wave data generated from the 15m depth contour to help fill in the gaps from where the fish sites weren't surveyed
fish <- read.csv("FISH_waves_1979_2010.csv") # wave data from historical fish sites
#Data cleanup
head(cont)
colnames(cont)
cont <- cont[ which(cont$BAD_FLAG == 0),] # remove the bad flags
cont$X2011 <- NULL # remove 2011 and 2012 data so both datasets have same year range
cont$X2012 <- NULL
cont$BAD_FLAG <- NULL
head(fish)
colnames(fish)
fish<-fish%>% dplyr::filter(Site!="GUA-01310") #remove this site because it doesn't have a lat and long
fish<-fish%>% dplyr::filter(fish$BAD_FLAG == 0) #remove this site because it doesn't have a lat and long
fish$Wave.Power..kwhr.m. <- NULL
fish$ISL <- substr(fish$Site, 1, 3)
fish$Site <- NULL
fish$BAD_FLAG <- NULL
fish <- fish[,c(1,2,35,3:34)] # reorder
all <- rbind(fish, cont) # combined data sets
nrow(fish)
nrow(cont)
# calculate mean and median per coordinate across all years- Tom has concerns about using mean as a summary statistic
all_2<-all %>%
rowwise() %>%
dplyr::mutate(means = mean(c_across(X1979:X2010), na.rm=T),medians = median(c_across(X1979:X2010), na.rm=T))
head(as.data.frame(all_2))
# save full wave action dataframe as a new data set
write.csv(all_2, "WaveActionPacific_1997_2010.csv")
# convert to spatial points data frame
xy <- all_2[,c(1,2)]
all_sp <- SpatialPointsDataFrame(coords = xy, data = all_2,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
### read in juvenile data
juv<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_GENUS.csv")
#Clean up juvenile site data
juv<-juv%>%dplyr::filter(OBS_YEAR >2013)
levels(juv$MISSIONID)
juv<-juv[!juv$MISSIONID %in% c("MP1410","MP1512","MP1602","SE1602","MP2006"),]
juv$Year_Island<-paste(juv$OBS_YEAR,juv$ISLAND,sep="_")
juv$Year_Region<-paste(juv$OBS_YEAR,juv$REGION,sep="_")
juv<-juv[!juv$Year_Island %in% c("2017_Baker","2017_Jarvis","2017_Howland"),]
juv<-droplevels(juv);levels(juv$MISSIONID)
View(juv)
juvS<-subset(juv,GENUS_CODE=="SSSS")
juvS <- subset(juvS,select=c(ISLAND,SITE,LATITUDE,LONGITUDE)) # remove extra columns -- only need site name + coords
colnames(juvS)
#Read in islands shapefile
islands<-st_read("U:/GIS/Data/Pacific/islands.shp")
# WAVE ACTION CALCULATOR #
## this code assigns wave action per juvenile coral site using two wave data files
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
library(ggsn)
library(ggspatial)
library(ggrepel)
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # wave data generated from the 15m depth contour to help fill in the gaps from where the fish sites weren't surveyed
fish <- read.csv("FISH_waves_1979_2010.csv") # wave data from historical fish sites
#Data cleanup
head(cont)
colnames(cont)
cont <- cont[ which(cont$BAD_FLAG == 0),] # remove the bad flags
cont$X2011 <- NULL # remove 2011 and 2012 data so both datasets have same year range
cont$X2012 <- NULL
cont$BAD_FLAG <- NULL
head(fish)
colnames(fish)
fish<-fish%>% dplyr::filter(Site!="GUA-01310") #remove this site because it doesn't have a lat and long
fish<-fish%>% dplyr::filter(fish$BAD_FLAG == 0) #remove this site because it doesn't have a lat and long
fish$Wave.Power..kwhr.m. <- NULL
fish$ISL <- substr(fish$Site, 1, 3)
fish$Site <- NULL
fish$BAD_FLAG <- NULL
fish <- fish[,c(1,2,35,3:34)] # reorder
all <- rbind(fish, cont) # combined data sets
nrow(fish)
nrow(cont)
# calculate mean and median per coordinate across all years- Tom has concerns about using mean as a summary statistic
all_2<-all %>%
rowwise() %>%
dplyr::mutate(means = mean(c_across(X1979:X2010), na.rm=T),medians = median(c_across(X1979:X2010), na.rm=T))
head(as.data.frame(all_2))
# convert to spatial points data frame
xy <- all_2[,c(1,2)]
all_sp <- SpatialPointsDataFrame(coords = xy, data = all_2,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
### read in juvenile data
juv<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_GENUS.csv")
#Clean up juvenile site data
juv<-juv%>%dplyr::filter(OBS_YEAR >2013)
levels(juv$MISSIONID)
juv<-juv[!juv$MISSIONID %in% c("MP1410","MP1512","MP1602","SE1602","MP2006"),]
juv$Year_Island<-paste(juv$OBS_YEAR,juv$ISLAND,sep="_")
juv$Year_Region<-paste(juv$OBS_YEAR,juv$REGION,sep="_")
juv<-juv[!juv$Year_Island %in% c("2017_Baker","2017_Jarvis","2017_Howland"),]
juv<-droplevels(juv);levels(juv$MISSIONID)
View(juv)
juvS<-subset(juv,GENUS_CODE=="SSSS")
juvS <- subset(juvS,select=c(ISLAND,SITE,LATITUDE,LONGITUDE)) # remove extra columns -- only need site name + coords
colnames(juvS)
#Read in islands shapefile
islands<-st_read("U:/GIS/Data/Pacific/islands.shp")
#Plotting the wave and juvenile data for a subset of islands to check overlap
#Helpful website for plotting maps with ggplot https://r-spatial.org/r/2018/10/25/ggplot2-sf-2.html
Plot_WaveJuv<-function(d1,d2,d3,waveISL="OAH",juvISL="Oahu",xlim1,xlim2,ylim1,ylim2){
ggplot(data = d1) +
geom_sf() +
geom_point(data = subset(d2,ISL==waveISL), aes(x = x, y = y), size = 2, shape = 21, fill = "slateblue3") +
geom_point(data = subset(d3,ISLAND==juvISL),aes(x = LONGITUDE, y = LATITUDE), size = 2, shape = 8, color = "darkorange1") +
coord_sf(xlim = c(xlim1, xlim2), ylim = c(ylim1, ylim2), expand = FALSE)+
theme(panel.grid.major = element_line(color = gray(0.5), linetype = "dashed",
size = 0.5), panel.background = element_rect(fill = "aliceblue"))+
annotation_scale(location = "bl", width_hint = 0.4)
}
extent(subset(all_2,ISL=="OAH")) # identify extent of coordinates
Plot_WaveJuv(islands,all_2,juv,"OAH","Oahu",-158.5, -157.5,21.2, 21.8)
extent(subset(all_2,ISL=="KAH")) # identify extent of coordinates
Plot_WaveJuv(islands,all_2,juv,"KAH","Kahoolawe",-156.72, -156.5,20.5, 20.61)
extent(subset(all_2,ISL=="MAU"))
Plot_WaveJuv(islands,all_2,juv,"MAU","Maug",145.2, 145.25,20, 20.05)
extent(subset(all_2,ISL=="PAL"))
Plot_WaveJuv(islands,all_2,juv,"PAL","Palmyra",-162.2, -161.99,5.85,5.925)
extent(subset(all_2,ISL=="KIN"))
Plot_WaveJuv(islands,all_2,juv,"KIN","Kingman",-162.49, -162.3,6.35,6.47)
# convert juv data to spatial points data
xy_juv <- juvS[,c(4,3)]
juv_sp <- SpatialPointsDataFrame(coords = xy_juv, data = juvS,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
str(juv_sp)
### calculate the mean wave action values within 250m radius of each juv point
# source expanding extract function
source("M:/Environmental Data Summary/HelperCode/ExpandingExtract_Flex.R")
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
sites_waves
ExpandingExtract_Flex
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
all_sp
juv_sp
ExpandingExtract_Flex
ExpandingExtract_Flex
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
ExpandingExtract_Flex
### calculate the mean wave action values within 250m radius of each juv point
# source expanding extract function
source("M:/Environmental Data Summary/HelperCode/ExpandingExtract_Flex.R")
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
ExpandingExtract_Flex
head(sites_waves)
# convert juv data to spatial points data
xy_juv <- juvS[,c(4,3)]
juv_sp <- SpatialPointsDataFrame(coords = xy_juv, data = juvS,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
### calculate the mean wave action values within 250m radius of each juv point
# source expanding extract function
source("M:/Environmental Data Summary/HelperCode/ExpandingExtract_Flex.R")
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
ExpandingExtract_Flex
sessionInfo()
library(dplyr)
library(sp)
library(sf)
library(raster)
library(ncf) # for gcdist()
library(ggsn)
library(ggspatial)
library(ggrepel)
setwd("M:/Environmental Data Summary/DataDownload/WaveEnergySwath")
list.files()
### read in wave data
cont <- read.csv("15m_contours.csv") # wave data generated from the 15m depth contour to help fill in the gaps from where the fish sites weren't surveyed
fish <- read.csv("FISH_waves_1979_2010.csv") # wave data from historical fish sites
#Data cleanup
head(cont)
colnames(cont)
cont <- cont[ which(cont$BAD_FLAG == 0),] # remove the bad flags
cont$X2011 <- NULL # remove 2011 and 2012 data so both datasets have same year range
cont$X2012 <- NULL
cont$BAD_FLAG <- NULL
head(fish)
colnames(fish)
fish<-fish%>% dplyr::filter(Site!="GUA-01310") #remove this site because it doesn't have a lat and long
fish<-fish%>% dplyr::filter(fish$BAD_FLAG == 0) #remove this site because it doesn't have a lat and long
fish$Wave.Power..kwhr.m. <- NULL
fish$ISL <- substr(fish$Site, 1, 3)
fish$Site <- NULL
fish$BAD_FLAG <- NULL
fish <- fish[,c(1,2,35,3:34)] # reorder
all <- rbind(fish, cont) # combined data sets
nrow(fish)
nrow(cont)
# calculate mean and median per coordinate across all years- Tom has concerns about using mean as a summary statistic
all_2<-all %>%
rowwise() %>%
dplyr::mutate(means = mean(c_across(X1979:X2010), na.rm=T),medians = median(c_across(X1979:X2010), na.rm=T))
head(as.data.frame(all_2))
# save full wave action dataframe as a new data set
write.csv(all_2, "WaveActionPacific_1997_2010.csv")
# convert to spatial points data frame
xy <- all_2[,c(1,2)]
all_sp <- SpatialPointsDataFrame(coords = xy, data = all_2,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
### read in juvenile data
juv<-read.csv("T:/Benthic/Data/REA Coral Demography & Cover/Summary Data/Site/BenthicREA_sitedata_GENUS.csv")
#Clean up juvenile site data
juv<-juv%>%dplyr::filter(OBS_YEAR >2013)
levels(juv$MISSIONID)
juv<-juv[!juv$MISSIONID %in% c("MP1410","MP1512","MP1602","SE1602","MP2006"),]
juv$Year_Island<-paste(juv$OBS_YEAR,juv$ISLAND,sep="_")
juv$Year_Region<-paste(juv$OBS_YEAR,juv$REGION,sep="_")
juv<-juv[!juv$Year_Island %in% c("2017_Baker","2017_Jarvis","2017_Howland"),]
juv<-droplevels(juv);levels(juv$MISSIONID)
View(juv)
juvS<-subset(juv,GENUS_CODE=="SSSS")
juvS <- subset(juvS,select=c(ISLAND,SITE,LATITUDE,LONGITUDE)) # remove extra columns -- only need site name + coords
colnames(juvS)
#Read in islands shapefile
islands<-st_read("U:/GIS/Data/Pacific/islands.shp")
#Plotting the wave and juvenile data for a subset of islands to check overlap
#Helpful website for plotting maps with ggplot https://r-spatial.org/r/2018/10/25/ggplot2-sf-2.html
Plot_WaveJuv<-function(d1,d2,d3,waveISL="OAH",juvISL="Oahu",xlim1,xlim2,ylim1,ylim2){
ggplot(data = d1) +
geom_sf() +
geom_point(data = subset(d2,ISL==waveISL), aes(x = x, y = y), size = 2, shape = 21, fill = "slateblue3") +
geom_point(data = subset(d3,ISLAND==juvISL),aes(x = LONGITUDE, y = LATITUDE), size = 2, shape = 8, color = "darkorange1") +
coord_sf(xlim = c(xlim1, xlim2), ylim = c(ylim1, ylim2), expand = FALSE)+
theme(panel.grid.major = element_line(color = gray(0.5), linetype = "dashed",
size = 0.5), panel.background = element_rect(fill = "aliceblue"))+
annotation_scale(location = "bl", width_hint = 0.4)
}
extent(subset(all_2,ISL=="OAH")) # identify extent of coordinates
Plot_WaveJuv(islands,all_2,juv,"OAH","Oahu",-158.5, -157.5,21.2, 21.8)
extent(subset(all_2,ISL=="KAH")) # identify extent of coordinates
Plot_WaveJuv(islands,all_2,juv,"KAH","Kahoolawe",-156.72, -156.5,20.5, 20.61)
extent(subset(all_2,ISL=="MAU"))
Plot_WaveJuv(islands,all_2,juv,"MAU","Maug",145.2, 145.25,20, 20.05)
extent(subset(all_2,ISL=="PAL"))
Plot_WaveJuv(islands,all_2,juv,"PAL","Palmyra",-162.2, -161.99,5.85,5.925)
extent(subset(all_2,ISL=="KIN"))
Plot_WaveJuv(islands,all_2,juv,"KIN","Kingman",-162.49, -162.3,6.35,6.47)
# convert juv data to spatial points data
xy_juv <- juvS[,c(4,3)]
juv_sp <- SpatialPointsDataFrame(coords = xy_juv, data = juvS,
proj4string = CRS("+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"))
str(juv_sp)
### calculate the mean wave action values within 250m radius of each juv point
# source expanding extract function
source("M:/Environmental Data Summary/HelperCode/ExpandingExtract_Flex.R")
sites_waves <- ExpandingExtract_Flex(Data = all_sp, SurveyPts = juv_sp,
Dists = seq(0, 4000, by = 50),Data_Col = "medians",REPORT = T) # you may not want to keep sites that have wave data from 4km away, but you can drop these sites later in the script
sessionInfo()
